\section{SaUCy}
\label{sec:saucy}

Using ILC, we build a concrete, executable implementation of the UC framework,
dubbed SaUCy. Then, we demonstrate the versatility of SaUCy in three ways:
\begin{enumerate}[leftmargin=*]
\item We define a protocol composition operator and its associated composition theorem.
\item We walk through an instantiation of UC commitments.
\item We use ILC's type system to reason about ``reentrancy,'' a subtle definitional issue in UC that has only recently been studied.
\end{enumerate}


%\begin{figure}
%  \centering
%  \includegraphics[width=0.4\linewidth]{graphics/execUC}
%  \caption{UC execution.}
%  \label{fig:execUC}
%\end{figure}

\subsection{The UC Framework, Concretely}
\label{subsec:concrete-uc}

\setlength\intextsep{0pt}
\setlength{\columnsep}{10pt}
\begin{wrapfigure}{R}{0.15\textwidth}
\centering
\includegraphics[width=0.15\textwidth]{graphics/execUC}
\caption{\textsf{execUC}.}
\label{fig:execUC-diagram}
\end{wrapfigure}
The first challenge in SaUCy is to define the UC execution model in ILC.  In
principle, this is simple and routes messages as illustrated in
Figure~\ref{fig:execUC-diagram} to the right. For demonstration, we only show
the case of two-party protocols (\`{a} la Simplified
UC~\cite{canetti2015simpler}), which will suffice for our example of
instantiating universally composable commitments.  Also, we will only aim to
show the case of \emph{static} corruptions, in which parties are corrupted at
the onset of the execution. This is in contrast to \emph{adaptive} corruptions,
in which parties can be corrupted as the execution proceeds.

\todo{Inline wrappers.} The details require some careful programming, since the
adversary gets to send messages on behalf of corrupted parties.
\lstinputlisting[style=myilc]{listings/simp-suc.ilc}
\noindent
The function \textsf{execUC} is parameterized by an environment \textsf{z},
protocol parties \textsf{p} and \textsf{q}, an adversary \textsf{a}, an ideal
functionality \textsf{f}, a security parameter \textsf{k}, a random bitstring
\textsf{r}, and a static corruption model \textsf{crupt :: !Crupt}. The
\textsf{Crupt} datatype is defined below, with its variants denoting the cases
when party \textsf{p} is corrupt, party \textsf{q} is corrupt, or no party is
corrupt, respectively.

\lstinputlisting[style=myilc]{listings/crupt.ilc}

\noindent It first allocates the required channels (see
Figure~\ref{fig:execUC-diagram}), and then splits a random bitstring,
distributing pieces to each of the parties as they are run.  Note that each
protocol party is run in a wrapper function, which determines its behavior based
on whether or not it is corrupted. If a party is corrupted, then the adversary
masquerades as the party.

Note that for space and readability, we elide channel allocation
and distribution (with ellipses) and abbreviate the type signature (e.g.,
$X_{\mathsf{z}}$ is the type of \textsf{z}), but more details can be found
in Appendix~\ref{sec:full-execUC}.

%$\{(\mathsf{m}_{\mathsf{f}},\mathsf{m}_{\mathsf{a}},\mathsf{m_{\mathsf{z}}) \mid \mathsf{m}_{\mathsf{f}} || (\mathsf{m}_{\mathsf{a}} || (\mathsf{R} || (\mathsf{R} || \mathsf{m}_{\mathsf{z}}))) => \mathsf{m}_{\mathsf{e}}}\}$

\begin{comment}
\begin{itemize}[leftmargin=*]
  \item \emph{Environment.} The environment's program defines interactions with
    the protocol parties and the adversary, which have different programs in the
    real world and the ideal world (see below). Its job is to distinguish which
    of the worlds it is interacting with.
  \item \emph{Protocol.} In the real world, the program of the protocol parties
    correspond to actual programs for running the protocol. In the ideal world,
    the protocol parties are simply dummy parties, which relay messages between
    the environment and the functionality.
  \item \emph{Adversary.} In the real world, the adversary is simply the dummy
    adversary, which relays messages between the environment and either the
    functionality or a corrupted party. In the ideal world, the adversary is a
    simulator, which must mimic the attack of any real world adversary, but in
    the ideal world.
  \item \emph{Functionality.} In the real world, the functionality is any
    functionality that the real world protocol makes calls to (if any). In the
    ideal world, the functionality is the specification for the protocol under
    analysis.
  \item \emph{Security parameter.} Each process is handed a security parameter
    (a natural number), and must run in a number of steps polynomial in this
    security parameter. We have more to say on this later.
  \item \emph{Corruptions.} The possible corruption models are either party
    \textsf{p} is corrupt, party \textsf{q} is corrupt, or no parties are
    corrupt, which are defined in the following datatype:
    \lstinputlisting[style=myilc]{listings/crupt.ilc}
\end{itemize}
\end{comment}

%For a real world execution, the protocol parties contain code for running the
%actual protocol under analysis, the adversary is the dummy adversary, and the
%ideal functionality is any functionality that the protocol makes calls to (if
%any). For an ideal world execution, the protocol parties are simply dummy
%parties, the adversary is a simulator, and the ideal functionality is a
%specification for the protocol under analysis. The environment has the ability
%to interact with each of the executions as they evolve. For the simulation to be
%good, the environment should not be able to distinguish which of the executions
%it is interacting with.

\subsection{Probabilistic Polynomial Time in ILC}
\label{subsec:ppt}
The goal of cryptography reduction is to relate every bad event in the protocol to a \emph{probabilistic polynomial time computation} that solves a hard problem.
The ILC typing rules do not guarantee termination, let alone polynomial time normalization, so we must tackle this in metatheory.
Also, since ILC is effectively deterministic (confluent), we will need to express random choices some other way.
To meet these needs we define a judgment about ILC terms that take a security parameter and a  stream of random bits.

\begin{definition}[Polynomial time normalization]
  \begin{comment}
  Consider a term \textsf{e} with the type
  \[\emptyctxt ;\emptyctxt |- \mathsf{e} : \tyBang{\tyNat} \multimap \tyBang{[\tyBit]}~{\multimap}_m~\tyBang{\tyBit},\]
  where the first argument is a security parameter and the second argument is a
  random bitstring.\footnote{The definition of polynomial time normalization
    applies similarly to a term \textsf{e} of type $\tyBit$ where the security
    parameter and random bitstring are free variables in \textsf{e}.} We say
  that \textsf{e} is polynomial time normalizable, written \textsf{poly(e)}, if
  for all security parameters \textsf{k} and all random bitstrings \textsf{r},
  where the length of \textsf{r} is polynomial in the security parameter
  \textsf{k}, the term \textsf{e k r} normalizes to a value \textsf{v} in a
  polynomial (in \textsf{k}) number of steps.
  \end{comment}
  The judgment that \textsf{e} is polynomial time normalizable, written \textsf{PPT e}, is defined as follows:
  \begin{mathpar}
    \Infer{ppt}
    {\emptyctxt ~; \emptyctxt |- e : \tyBang{\tyNat} \multimap \tyBang{[\tyBit]} {\multimap}_{m}
      \tyBang{\tyBit}\\
    \forall~\mathsf{k} \in \tyNat.~\forall~r \in {[\tyBit]}^{(poly(\mathsf{k}))}.~\mathsf{e~!k~!r}~{->}^{poly(\mathsf{k})}~\mathsf{v}}
    {\keyword{PPT}~ \mathsf{e} }
  \end{mathpar}
  This says that if for all security parameters \textsf{k} and all bitstrings
  \textsf{r} with length polynomial in \textsf{k} the term \textsf{e~!k~!r}
  normalizes to a value \textsf{v} in $poly(\mathsf{k})$ steps.
  Note that the normalization is polynomial time for all $\mathsf{r}$.
\end{definition}

\begin{definition}[Value Distribution] 
  Because processes are confluent, we know that if $\mathsf{e~!k~!r}~{->}^{*}~\mathsf{v}$
  then the value $\mathsf{v}$ is unique.  We can therefore define the
  probability distribution ensemble $D(\mathsf{e}) = \{ D_{\mathsf{e,k}}
  \}_\mathsf{k}$ of values given a uniform distribution $U_k$ over
  $\mathsf{k}$-bit strings $\mathsf{r}$, where
\[
D_{\mathsf{e},\mathsf{k}}(\mathsf{v}) = \sum_{\mathsf{r} \in R} U_{\mathsf{k}}(\mathsf{r}), \quad \textnormal{for~} R = \{ \mathsf{r} ~|~ \mathsf{e~!k~!r}~{->}^{*}~\mathsf{v} \}.
\]
\end{definition}

\begin{definition}[Indistinguishable]
What remains is to define a notion of indistinguishability for value distributions. ${D(\mathsf{e}_1) \sim D(\mathsf{e}_2)}$. However, we need to be clear on when polynomial time normalization is an assumption or a proof obligation.
  To simplify things later, we define a partial order $\mathsf{e}_1 \le \mathsf{e}_2$, which captures that $e_2$ must be PPT if $e_1$ is PPT, and if so, that their value distributions are similar.
  \begin{mathpar}
    \Infer{indist}
    {\keyword{PPT}~ \mathsf{e}_1 \implies (\keyword{PPT}~ \mathsf{e}_2 ~~\keyword{and}~~
    {D(\mathsf{e}_1) \sim D(\mathsf{e}_2)})}
    {   \qquad \mathsf{e}_1 \le \mathsf{e}_2 }
  \end{mathpar}
\end{definition}

\subsection{Defining UC Security in ILC}
\label{subsec:uc}
The central security definition in UC is protocol emulation.  The guiding
principle is that $\pi$ emulates $\phi$ if the environment cannot distinguish between
the two protocols.  Our first attempt is the following, where $\mc{S}$ is the
simulator that translates every attack in the real world into an attack
expressed in the ideal world:
\begin{mathpar}
  \Infer{\st{emulate}}
        {\forall~\mc{Z}.~ 
         \mathsf{execUC}\ \mc{Z}\ \pi\ \mc{F}_1\ {\mathbbm{1}}_\mc{A} \le
         \mathsf{execUC}\ \mc{Z}\ \phi\ \mc{F}_2\ \mc{S}}
    {\mc{S} \entails (\pi, \mc{F}_1) \approx (\phi, \mc{F}_2)}
\end{mathpar}
To note a few notation choices, we make the functionality explicit, so emulation
is a relationship between protocol-functionality pairs.  Here,
$\mathbbm{1}_\mc{A}$ is the dummy adversary, which just relays messages between
the environment and the parties. We elide the standard dummy lemma that shows
this is without loss of generality; the intuition is that whatever an adversary
can do, the environment can achieve using $\mathbbm{1}_\mc{A}$.

%\[
%(\pi, \mc{F}_1) \overset{\mc{S}} \le (\phi, \mc{F}_2)
%\]
%\[
%S ~\keyword{proves}~ (\pi, \mc{F}_1) ~\keyword{emulates}~ (\phi, \mc{F}_2).
%  \]
%  Since the simulator tranlates attacks $\mc{A}$ to the real world, we treat $\mc{S}$ as a function, so $\mc{S A}$ is the ideal world adversary simulating $\mc{A}$.

%% Since emulation means that any attack on $\pi$ is also on $\phi$.
%% We have to translate \emph{attacker behaviors} of an arbitrary real world adversary $\mc{A}$ to a simulated adversary $\mc{(S~A)}$ in the ideal world.

Unfortunately this simple definition turns out to be vacuous: a degenerate
protocol $\pi$ can emulate anything simply failing to be $\keyword{PPT}$, e.g. by
diverging. To put it another way, the problem is the definition imposes a proof
obligation on the simulator $\mc{S}$ but not on $\pi$.  What we want to say is
that the \emph{real world} protocol $(\pi, \mc{F}_1)$ must be well behaved
whenever the \emph{ideal world} $(\phi, \mc{F}_2)$ is.  However, even a reasonable
protocol can result in non-PPT executions if paired with a divergent
environment.  In fact, giving a precise but composable notion of polynomial-time
for interactive processes has been an ongoing challenge in UC. In GNUC, the
approach is to define a well behaved environment, independently of its execution
context---roughly that the total size of its outgoing messages is bounded by a
polynomial, and that its running time is bounded if its total received input
size is bounded~\cite{hofheinz2015gnuc}. This notion is composable as desired,
although its use requires additional distinctions between ``invited'' and
``uninvited'' messages, which seems cluttered. RSIM makes analogous
choices~\cite{backes2007reactive}. We think these could be applied as easily in
ILC, but our goal here is to provide a simpler notion.

We define protocol emulation by requiring a simulation in both directions, so every behavior in the ideal world must correspond to a behavior in the real world and vice versa.
\begin{definition}[Protocol Emulation]
  The judgment that one protocol-functionality pair $(\pi, \mc{F}_1)$  securely emulates another $(\phi, \mc{F}_2)$ (as proven the simulators $\mc{S}_\mc{R},\mc{S}_\mc{I}$) is defined as
\begin{mathpar}
  \Infer{{emulate}}
        {\forall~\mc{Z}.~ 
         \mathsf{execUC}\ \mc{Z}\ \phi\ \mc{F}_2\ \mathbbm{1}_\mc{A} \le
         \mathsf{execUC}\ \mc{Z}\ \pi\ \mc{F}_1\ (\mc{S_\mc{R}}) \\\\
         \ \ \ \ \ \ \ \ ~\mathsf{execUC}\ \mc{Z}\ \pi\ \mc{F}_1\ \mathbbm{1}_\mc{A} \le
         \mathsf{execUC}\ \mc{Z}\ \phi\ \mc{F}_2\ (\mc{S}_\mc{I})}
    {\mc{S_\mc{R},S_\mc{I}} \entails (\pi, \mc{F}_1) \approx (\phi, \mc{F}_2)}
\end{mathpar}
\end{definition}
We remark that this definition goes against the usual UC convention of requiring simulation in one direction only. Requiring one direction is preferred intuitively because it should be OK if the protocol is even more secure than its specification. Requiring both could be too restrictive.
However, the benefit is this simplifies the polynomial time notion: vacuous protocols are clearly ruled out by the top condition, and both simulations are only required to be \keyword{PPT} when $\mc{Z}$ is.
Furthermore, we have not found it too restrictive.

%%   \begin{mathpar}
%%   \Infer{\st{emulate}}
%%         {\forall~\mc{A}~\mc{Z}.~ \keyword{PPT}~(\mathsf{execUC}~\mc{Z}~\phi~1_\mc{A}~\mc{F}_2) => \\\\
%%   \keyword{PPT}~(\mathsf{execUC}~\mc{Z}~\pi~\mc{S_\mc{R}}~\mc{F}_1)
%% \\\\
%%          \mathsf{execUC}\ \mc{Z}\ \pi\ \mc{F}_1\ \mc{A} \le
%%          \mathsf{execUC}\ \mc{Z}\ \phi\ \mc{F}_2\ (\mc{S}~\mc{A})}
%%         {(\pi, \mc{F}_1) \overset{\mc{S}}\le (\phi, \mc{F}_2)}
%%   \end{mathpar}
  

%
%
%We therefore need to express a judgment $\keyword{Good}$ to describe environments that are well behaved in the ideal world:
%\begin{mathpar}
%  \Infer{good}
%        {\keyword{PPT}~(\mathsf{execUC}~\mc{Z}~\phi~1_\mc{A}~\mc{F}_2)}
%        {\keyword{Good}~\phi~\mc{F}_2~\mc{Z}}
%\end{mathpar}
%% To resolve this concern, we say that every \emph{benign behavior} in the ideal world must translate to. We require an additional simulator in the real world $\mc{S_\mc{R}}$      says that every benign behavior in the ideal world must correspond to a benign environment in the real world. To characteris
%% \noindent Notice that this constraint has the dummy adversary $1_\mc{A}$.
%% %, even though it is written for the ideal world, unlike in the dummy lemma.
%% This is without loss of generality in the sense that $\keyword{Good}~\phi~\mc{F}_2~Z$ implies that for any $\mc{A}$, we could have a $\mc{Z'}$ such that
%% \[
%% \mathsf{execUC}~\mc{Z} ~\phi  ~\mc{A}~\mc{F}_2 \le
%% \mathsf{execUC}~\mc{Z'}~\phi~1_\mc{A}~\mc{F}_2
%% \]


\subsection{A composition theorem in SaUCy}
\label{subsec:composition}

\begin{figure}
  \centering
  \includegraphics[width=0.85\linewidth]{graphics/protocol-composition}
  \caption{Protocol composition diagram.}
  \label{fig:protocol-composition}
\end{figure}

As a first demonstration of SaUCy, we work through the development of a composition
operator, and give a theorem explaining its use.
\begin{definition}[UC realizes]
To set out, we introduce the notation of ``realizes,'' which views a protocol as a way of realizing a specification functionality $\mc{F}_{2}$ from a setup assumption functionality $\mc{F}_1$.
%  if $\keyword(\mc{Z}, \pi, \mc{F}_0, \mc{A}_{\mathbbm{1}})$, then
%  $|- \keyword{polyUC}(\mc{Z}, \pi_{\mathbbm{1}}, \mc{F}_1, \mc{S})$, and the
  %  following statistical indistinguishability relation holds
\begin{mathpar}
  \Infer{realizes}
  {(\pi,~\mc{F}_1) \approx (\mathbbm{1}_\pi, \mc{F}_2)}
  {\mc{F}_1 \yrightarrow{$\pi$} \mc{F}_2}
  \end{mathpar}
\end{definition}
This notation is convenient because it suggests a categorical approach to defining the composition theorem.

\begin{theorem}[Composition Theorem]
  \begin{mathpar}
  \Infer{realizes}
  {\mc{F}_1 \yrightarrow{$\pi$} \mc{F}_2 \\ 
  \mc{F}_2 \yrightarrow{$\phi$} \mc{F}_3}
  {\mc{F}_1 \yrightarrow{$\pi \circ \phi$} \mc{F}_3}
  \end{mathpar}
\end{theorem}

The idea is that the $\pi \circ \rho$ can be defined in a natural way, where the ideal functionality channel of $\pi$ is connected to the environment channel of $\rho$, as illustrated in illustrated in Figure~\ref{fig:protocol-composition} and given in Figure~\ref{fig:composition-operator}.
\begin{figure}
\lstinputlisting[style=myilc]{listings/compose.ilc}
\caption{Protocol composition operator.}
\label{fig:composition-operator}
\end{figure}

\noindent To prove the theorem we construct the simulators $S_{\mc{R},\pi} \circ S_{\mc{R},\phi}$ and $S_{\mc{I},\pi} \circ S_{\mc{I,\phi}}$ in the natural way as well (given in the Appendix).
What remains is a reduction proof. Given an environment $\mc{Z}$ that can distinguish $(\pi \circ \phi, \mc{F}_1)$ from $(1_\pi, \mc{F}_3)$, we must construct $\mc{Z}^{*}$ that distinguishes either
$(\pi,\mc{F}_1)$ from $(1_\pi,\mc{F}_2)$ or
$(\phi,\mc{F}_2)$ from $(1_\pi,\mc{F}_3)$.
The main idea behind the proof is to observe that the protocol $\pi$ can be folded into the definition of an environment.% $\mc{Z}^{*}[\pi]$ on one hand \todo{finish} and this is an adequate environment for  represents arbitrary other protocols that may provide inputs to $\phi$ as a subroutine.

\todo{Proof sketch}

\paragraph{Other notions of composition}
Other composition operators can be built in a similar way.
Normally UC features a built-in ``universal composition'' that does multiplexing by  session IDs. This can easily be defined for protocols. \todo{say we leave for future work}
Joint state composition is a theorem pertaining to this.


\subsection{Instantiating UC Commitments}
\label{subsec:example}
We walk through the development of a UC instantiation for commitments.  UC
commitments can be instantiated with standard cryptographic assumptions, for
example the RSA problem.  Also rely on a ``trusted setup'', or common reference
string, essentially public parameters generated ahead of time (modeled as an
ideal functionality $\Func_{\textsc{crs}}$).

Instantiation proofs in UC follow a standard rhythm. We start with a security
definition as an ideal functionality, give the protocol, construct a simulator,
and finally complete the relational analysis on paper.  UC commitments are
reasoned to be secure assuming a common reference string is suitably generated.
To model the cryptography we extend ILC with additional syntax.

The functionality FCom has already been defined.
\todo{Recap the proof obligation}

\paragraph{Extending ILC with cryptographic primitives.}
\todo{Still lots of changes to make here.} UC Commitments are realized from
cryptographic primitives, such as pseudorandom trapdoor permutations. This
requires us to extend the syntax. The semantics are written in terms of the
cryptographic objects themselves, and we still arrive at a computational
reduction for our security proof.

The new syntactic forms are \textsf{kgen}, \textsf{tdp}, \textsf{inv}, and
\textsf{hc} with the static and dynamic semantics shown in
Figure~\ref{fig:extended-ilc}. The key generation function \textsf{keygen}
generates, on input $1^n$ (security parameter), a random public key $v_{pk}$ and
a trapdoor $v_{td}$. The trapdoor permutation function \textsf{tdp} computes, on
input key $v_k$ and bitstring $v_{in}$, a bitstring $v_{out}$. The hardcore
predicate function \textsf{hc} generates, on input trapdoor permutation
$f_{v_k}$.

\input{figures/ilc/extended-syntax}

\[ G_{pk}(r) = \big(f_{pk}^{(3n)}(r), B(f_{pk}^{(3n-1)}(r)), \ldots, B(f_{pk}(r)), B(r)\big)\]

\lstinputlisting[style=myilc]{listings/prg.ilc}

\begin{algorithm}
\SetAlgorithmName{Protocol}{protocol}{List of Protocols}
\DontPrintSemicolon

\SetKwBlock{Parameters}{\textnormal{\textsf{Public strings}:}}{}
\Parameters{
  $\sigma$: Random string in $\{0,1\}^{4n}$\;
  ${pk}_0, {pk}_1$: Keys for generator $G_{k} \colon \{0,1\}^n \to \{0,1\}^{4n}$
}\smallskip
\SetKwBlock{Commit}{\textnormal{\textsf{Commit}($b$):}}{}
\Commit{
  $r \leftarrow \{0, 1\}^n$\;
  $x \coloneqq G_{{pk}_b}(r)$\;
  if $b=1$ then $x \coloneqq x \oplus \sigma$\;
  Send $(\mathsf{Commit}, x)$ to receiver.\;
  Upon receiving $(\mathsf{Commit}, x)$ from $A$, $B$ outputs $(\mathsf{Receipt})$.
}\smallskip

\SetKwBlock{Decommit}{\textnormal{\textsf{Decommit}($x$):}}{}
\Decommit{
  Send $(b, r)$ to receiver.\;
  Receiver checks $x = G_{{pk}_b}(r)$ for $b = 0$, or $x = G_{{pk}_b}(r) \oplus \sigma$
  for $b = 1$. If verification succeeds, then $B$ outputs $(\mathsf{Open}, b)$.
}
\caption{Universally Composable Commitment}
\label{alg:com}
\end{algorithm}

\begin{figure}
\lstinputlisting[style=myilc]{listings/ucc.ilc}
\caption{Universally composable commitment in ILC.}
\label{fig:ucc}
\end{figure}

\paragraph{Commitment Protocol.}
We defer the protocol to the appendix.

\paragraph{Defining the simulator.}

\paragraph{Relational argument.}

\subsection{Reentrancy in SaUCy}
\label{subsec:reentrancy}

The cryptography community has recently identified several subtleties in defining UC ideal functionalities that relate to reentrancy and the scheduling of concurrent code;
because of these issues some functionalities in the literature are ambiguous as ITMs~\cite{camenisch2016universal}.
Although concerning, these issues have no cryptographic flavor, but instead are better addressed from the PL viewpoint.
To illustrate, consider the following fragment of (untyped) ILC syntax, which allows an adversary to control the delivery schedule of messages from $P$ to $Q$ (an asynchronous channel):
\lstinputlisting[style=myilc]{listings/reentrant.ilc}
After receiving input from party $P$, it
notifies the adversary, then forks a background thread to wait for \textsf{OK} before
delivering the message.
This introduces a race condition: suppose input message $m_1$ is sent by $P$, but then the adversary $\mathcal A$, before sending \textsf{OK}, instead returns control to $\mathcal Z$, which passes $P$ a second input $m_2$. Now there are two queued messages; which one gets delivered first when the adversary sends \textsf{OK}?

To resolve this paradox, notice that fragment is untypeable in ILC.
The race condition occurs because of duplication of the read channel \textsf{frA}.
Since \textsf{frA} is linear in the function body, the function would not be typeable as intuitionistic as required by the \textsf{loop} construct.
Camenisch et al.~\cite{camenisch2016universal} identified several strategies for resolving this problem in UC, which in turn are expressible ILC. One approach is to make the process explicitly sequential, such that the arrival of a second message before the first is delivered causes execution to get stuck:
\lstinputlisting[style=myilc]{listings/reentrant-seq.ilc}
An alternative is to discard such messages arriving out of order, returning them to sender; this can be expressed in ILC using the external choice operator:
operator,
\lstinputlisting[style=myilc]{listings/reentrant-ignore.ilc}
