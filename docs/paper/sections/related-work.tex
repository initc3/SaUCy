\section{Related Work}
\label{sec:related}

We first touch on two views of cryptography that have emerged over the
years: symbolic cryptography and computational cryptography. Their distinctions
show up in our subsequent discussions of related process calculi, tools for
cryptographic reasoning, and variations of the UC framework.

\subsection{Symbolic vs. Computational Cryptography}
\label{subsec:symbolic-computational}

Approaches for reasoning about the security of cryptographic protocols generally
operate in one of two models---the symbolic model and the computational model---each
of which have their merits and drawbacks.

In the symbolic model, cryptographic operations are abstracted (and idealized)
as term algebras, and adversary capabilities are defined as deduction rules over
these terms~\cite{cortier2011survey}. Importantly, adversaries can make choices
nondeterministically, and so an attack trace will be found if there is
one. Viewing protocols from this abstract vantage point makes the analysis
relatively tractable, but because adversaries are nondeterministic, their
capabilities must be severely restricted. Therefore, it is possible to verify
protocols that are susceptible to simple attacks that lie outside the adversary
model.

In the computational model, cryptographic operations are functions over
bitstrings, and adversaries are probabilistic polynomial time (p.p.t.) Turing
machines. Here, security is defined in terms of the probability and
computational complexity of attacks. While this model is much more realistic and
security analysis admits much stronger guarantees, proofs are more complicated
and are, for the most part, done manually.

\subsection{Process Calculi}
\label{subsec:process-calculi}

Process calculi have a long and rich history. ILC occupies a point in this space
that is particularly suited to faithfully capturing interactive Turing machines
(and hence, computational cryptography), but plenty of existing process calculi
are also cryptographically-flavored and/or enjoy similar properties to ILC. We
survey some of them here.

Two of the early adaptations of process calculi for reasoning about
cryptographic protocols were the spi calculus~\cite{abadi1999calculus} and the
applied $\pi$-calculus~\cite{abadi2001mobile}, both of which extend the standard
$\pi$-calculus~\cite{milner1999communicating}. The spi calculus extends the
$\pi$-calculus with constructs for encryption and decryption, and develops a
technique for proving authenticity and secrecy properties of cryptographic
protocols via observational equivalence between spi calculus processes. The
applied $\pi$-calculus builds on this work, permitting a wider variety of
cryptographic primitives that can be defined by means of an equational theory.

A variety of tools for protocol analysis, some of which we discuss in the next
subsection, can trace their roots back to these works. They generally operate in
what is called the \emph{symbolic} model of cryptography (also known as the
Dolev-Yao model), in which cryptographic primitives are abstracted (and
idealized) as term algebras and adversary capabilities are defined as deduction
rules over these terms~\cite{cortier2011survey}. Although analyzing protocols
from this abstract vantage point makes the analysis relatively tractable, it is
possible to verify protocols that are susceptible to simple attacks that lie
outside the adversary model.

Hence, much follow-up work has focused on bridging the gap between this PL-style
of formalization and the \emph{computational} model of cryptography (the modus
operandi in cryptography), by outfitting process calculi with computational
semantics that considers issues of complexity and probability.

Lincoln \etal~\cite{lincoln1998probabilistic} give a computational semantics to
a variant of the $\pi$-calculus, which allows one to define communicating
probabilistic polynomial-time (p.p.t.) processes. In contrast to adversaries in
the symbolic model, which find attack traces nondeterministically, computational
adversaries can perform arbitrary p.p.t. computations to break
security. Additionally, they refine the notion of observational equivalence
between protocols introduced by Abadi and Gordon~\cite{abadi1999calculus} to
work in this new setting, and they are able to relate this new notion to
cryptographic ones such as indistinguishability.

Laud~\cite{laud2005secrecy} gives a computational and deterministic semantics to
the spi calculus, which additionally includes a type system for ensuring
well-typed protocols preserve the secrecy of messages given to it by users.

Mateus \etal~\cite{mateus2003composition} adapt the p.p.t. calculus by Lincoln
\etal~\cite{lincoln1998probabilistic} to explore (sequential) compositionality
properties in protocols. In their work, the security of a protocol is
established by a notion of emulation: A process $P$ emulates a process $Q$ if
for any adversary (context) $A[\cdot]$, the trace process of $A[P]$ is
observationally equivalent to the trace process of $B[Q]$ for ideal adversary
$B[\cdot]$. Compositionality follows naturally: A process that uses $Q$ can also use
$P$ as a secure implementation of $Q$.

\todo{Transition.}

Berger \etal~\cite{berger2001sequentiality} describe a type system for capturing
deterministic (sequential) computation in the $\pi$-calculus. The type system uses
affineness and stateless replication to achieve deterministic
computation. \todo{More details.}

Fowler \etal~\cite{fowler2018session} present a core linear lambda calculus with
session-typed channels and exception handling that enjoys a strong form of
confluence called the diamond property. Here, confluence is due to linearity of
buffer endpoints, so communication actions on different channels can be
performed in any order. Unfortunately, the calculus only extends to binary
sessions, so in our multiparty setting, we require a more sophisticated type
system to achieve confluence.

\subsection{Tools for Cryptographic Reasoning}
\label{subsec:tools}

As we touched on previously, tools for reasoning about the security of
cryptographic protocols generally come in one of two flavors: ones that operate
in the symbolic model and ones that operate in the computational model.

Symbolic UC~\cite{bohl2016symbolic} transports ideas from the UC framework to
the symbolic model of cryptography. In particular, they show that certain
aspects of the UC framework, such as ideal functionality specifications and UC
composition, still carry over to the symbolic model. They are also able to show
that certain results, such as the impossibility of UC commitments in the
standard model of cryptography, can still be observed in the symbolic model.

CertiCrypt~\cite{barthe2009formal} is a framework (built on
Coq~\cite{barras1997coq}) that supports machine-checked game-based proofs of
security. It includes tools to reason about the equivalence of probabilistic
programs, a relational Hoare logic, a theory of observational equivalence,
verified program transformations, and game-based techniques.  Their experience
shows that the type system and automated tactics provide valuable information in
debugging proofs. EasyCrypt~\cite{barthe2011computer} is follow-up work on
CertiCrypt, which permits more automation and shorter proof
scripts. \todo{Details on their imperative language?}

\subsection{Variations of the UC Framework}
\label{subsec:uc-variants}

\begin{enumerate}[leftmargin=*]
  \item Symbolic UC~\cite{bohl2016symbolic} transports ideas from the UC
    framework to the symbolic model of cryptography, in which cryptographic
    operations are abstracted as a term process algebra (specifically, a variant
    of the applied $\pi$-calculus) and adversary capabilities are defined by
    deduction rules over these terms. In particular, they show that certain
    aspects of the UC framework, such as ideal functionality specifications and
    UC composition, still carry over to the symbolic model. They are also able
    to show that certain results, such as the impossibility of UC commitments in
    the standard model of cryptography, can still be observed in the symbolic
    model. Although this abstract vantage point leads to simpler security proofs
    that can be amenable to automated reasoning, security guarantees derived
    from symbolic analyses are not as strong as those from computational
    analyses considered in UC and in cryptography more broadly.
  \item RSIM~\cite{backes2007reactive}.
  \item CertiCrypt~\cite{barthe2009formal} is a framework (built on
    Coq~\cite{barras1997coq}) that supports machine-checked game-based proofs of
    security. It includes tools to reason about the equivalence of probabilistic
    programs, a relational Hoare logic, a theory of observational equivalence,
    verified program transformations, and game-based techniques.  Their
    experience shows that the type system and automated tactics provide valuable
    information in debugging proofs.
  \item EasyCrypt~\cite{barthe2011computer} is follow-up work on CertiCrypt,
    which permits more automation and shorter proof scripts. \todo{Details on
      their imperative language?}
  \item ProVerif~\cite{blanchet2010proverif} is a tool for symbolically
    analyzing cryptographic protocols. It relies on the Horn theory approach, in
    which protocols and intruders are modeled as Horn theories. Protocols are
    analyzed with respect to an unbounded number of protocol sessions that may
    run concurrently and there is no bound on the number of messages an
    adversary can generate. Verifying security properties, such as secrecy,
    boils down to solving the derivation problem for Horn theories. Protocols
    can be specified as either Horn theories, or in a variant of the applied
    process calculus, which is translated into Horn theories.
  \item CryptoVerif~\cite{blanchet2007cryptoverif} works directly in the
    computational model. Produces game-based proofs valid for any number of
    sessions of the protocol in the presence of an active adversary. Games are
    represented in a process calculus inspired by the $\pi$-calculus,
    \cite{laud2005secrecy}, and \cite{mitchell2006probabilistic}. The calculus
    has a probabilistic semantics.
  \item Cryptol~\cite{lewis2003cryptol} allows for writing executable
    specifications of a protocol, which are amenable to testing, theorem
    proving, verifying equivalence to their own programs, and even generating
    code or hardware from the specification.
  \item $\text{F}^{\star}$~\cite{swamy2016dependent} is a language that functions as
    a proof assistant (SMT automation and constructive proofs using dependent
    types) as well as a general-purpose, verification-oriented programming
    language.
  \item Spi calculus~\cite{abadi1999calculus} is an extension of the
    $\pi$-calculus with cryptographic primitives. In the spi calculus, as in the
    $\pi$-calculus, channels can be passed over channels, and its scoping rules
    guarantee that an attacker cannot access a channel it is not explicitly
    given (scoping is the basis of security). The spi calculus allows expressing
    security guarantees as equivalences between spi calculus processes. For
    example, we can say that a protocol maintains the secrecy of a value $x$ by
    stating that the protocol with $x$ is equivalent to the protocol with $x'$,
    for every $x'$. Here, equivalence means equivalence in the eyes of an
    arbitrary environment that interacts with the protocol. \todo{They cannot
      take the standard bisimilarity relation as our notion of
      equivalence. Why?}

    Although equivalence makes reference to the environment, we do not need to
    give a model of the environment explicitly. Instead, the environment can be
    an arbitrary pi calculus process. In sum, their approach uses the powerful
    scoping constructs of the $\pi$-calculus, the definition of an environment as
    an arbitrary spi calculus process, and the representation of security
    properties (both integrity and security) as equivalences. However, the spi
    calculus does not include any notion of probability or complexity, so it can
    be a useful foundation for symbolic cryptography, but not computational
    cryptography.

    In $\pi$-calculus, the scope of a channel can change during a
    computation. When a process sends a restricted channel to a process outside
    the scope of the restriction, the scope is said to extrude. Why do we
    disallow extrusion in SaUCy? A central idea in spi calculus is to use
    restriction and extrusion to keep track of secret values.

    Another difference is that channels are bidirectional. 
  \item Applied $\pi$-calculus~\cite{abadi2001mobile} is a similar extension to
    the $\pi$-calculus. Here, there is no need to craft a special calculus and
    develop its proof techniques for each choice of cryptographic
    operation. Includes name restriction and variable restriction (as in the spi
    calculus), so fresh channels, nonces, and keys can be represented as new
    names. Attacks against protocols rely on equational properties.

    Example for one-way hash functions: Represent hash functions with a unary
    function symbol \textsf{h} (without any equational properties). The absence
    of an inverse for \textsf{h} models one-wayness. In comparison with spi
    calculus, the applied pi calculus permits a more uniform and versatile
    treatment of cryptographic functions (e.g., one-way hash functions,
    encryption/decryption, signatures, XOR), their variants, and their
    properties. \todo{Not clear to me why this is the case.} The spi calculus
    developed the idea that the context represents an active attacker, and
    equivalences capture authenticity and secrecy properties (same as here).
  \item Wysteria?~\cite{rastogi2014wysteria}
  \item Lambda auth?~\cite{miller2014authenticated}
  \item Fowler \etal~\cite{fowler2018session} develop a session typed
    programming language that is confluent. Only allows for fixed and two-party
    communications.
  \item Sequentiality and the $\pi$-calculus~\cite{berger2001sequentiality}. The
    authors developed a typed $\pi$-calculus that uses affineness and stateless
    replication to achieve deterministic computation. \todo{More details.}
  \item Secrecy types for a simulatable cryptographic
    library~\cite{laud2005secrecy}. They define a language for cryptographic
    protocols similar to the spi calculus and give it a semantics using the
    computational model of cryptography. They propose a type system for their
    language and show that if a protocol types, then it preserves the secrecy of
    messages given to it by users. The semantics of their calculus is
    deterministic. When complexity-theoretic security definitions are used,
    nondeterminism cannot be employed. The adversary is allowed to choose which
    thread handles the received message. 
  \item PPT process calculus for analysis of cryptographic
    protocols~\cite{mitchell2006probabilistic, lincoln1998probabilistic}. To
    avoid inconsistency between security and nondeterminism, messages are
    schedule probabilistically instead of nondeterministically. They prove that
    any process expression halts in polynomial time, and they define a form of
    asymptotic protocol equivalence that allows security properties to be
    expressed using observational equivalence, a standard relation that involves
    quantifying over all environments that might interact with the protocol. A
    limitation of deterministic or nondeterministic settings is the inability to
    analyze probabilistic protocols. Traditional nondeterministic scheduling
    means that an adversary has exponential computing power. With
    nondeterministic scheduling, an adversary can guess a $k$-bit key by
    concatenating $k$ bits. The combination of nondeterminism and bit-level
    representation of encryption keys renders any encryption function insecure.
  \item Composable crpytographic library with nested
    operations~\cite{backes2003composable}.
  \item Symmetric encryption in a simulatable Dolev-Yao style cryptographic
    library~\cite{backes2004symmetric}.
  \item Composition of cryptographic protocols in a p.p.t. process
    calculus~\cite{mateus2003composition}.
\end{enumerate}
