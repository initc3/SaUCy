\section{Introduction}
\label{sec:introduction}

In cryptography, a proof of security in the universal composability (UC) model
is the gold standard for demonstrating that a protocol carries out a
cryptographic task securely~\cite{canetti2001universally}. More specifically, a
protocol that is UC-secure enjoys the strongest notion of compositionality---it
maintains its security properties when run concurrently with arbitrary other
protocols.

In a nutshell, security proofs in UC follow the real/ideal
paradigm~\cite{goldreich1987play}. The security requirements of a given task are
defined as a program for a \emph{single trusted process} called an \emph{ideal
  functionality}, which runs in an imagined ideal world. This serves as a
specification of the desired security properties for a distributed protocol
achieving the task across \emph{many unstrusted processes}, which runs in the
real world. Roughly speaking, we say that a protocol $\pi$ \emph{emulates} an
ideal functionality $\mc{F}$ (i.e., it meets its specification) if every
adversarial behavior in the real world can also be exhibited in the ideal world.

While UC security proofs admit strong guarantees, this comes at the cost of
their formalization being quite complicated. Moreover, because the UC framework
only exists on paper, protocol descriptions, ideal functionalities, and other
proof artifacts for proving emulation are traditionally written in a combination
of prose and pseudocode, which makes them error-prone and difficult to
verify. Therefore, although the UC framework is widely used for on-paper proofs,
its modularity benefits have not been enjoyed in practical implementations.

Previous work, such as Symblic UC~\cite{bohl2016symbolic}, focus on
systematizing UC by transporting its ideas to the symbolic model of
cryptography, in which cryptographic operations are abstracted as a term
algebras and adversary capabilities are defined by deduction rules over these
terms. Although this abstract vantage point leads to simpler security proofs
that can be amenable to automated reasoning, security guarantees derived from
symbolic analyses are not as strong as those from computational analyses
considered in UC and in cryptography more broadly~\cite{cortier2011survey}.

This paper lays the groundwork for building a concrete implementation of the UC
framework, which admits computational proofs of security, in the form of a
process calculus called the Interactive Lambda Calculus (ILC). ILC represents
the first language-based approach to capturing the computational model
underlying UC: interactive Turing machines (ITMs). In the ITM model, execution
is essentially single-threaded. Processes pass control from one to another each
time a message is sent so that exactly one process is active at a given
time. And this choice is for good reason---it is necessary for computational
security proofs (specifically, cryptographic reductions) to go through.

It turns out that existing process calculi, such as the standard
$\pi$-calculus~\cite{milner1999communicating} and its cryptography-oriented
variants~\cite{abadi1999calculus, abadi2001mobile}, are not a good fit to
ITMs. They allow for non-confluent reductions by design, which are not
expressible in ITMs and hence, do not have a computational interpretation.
Therefore, to faithfully capture the computational model underlying UC, ILC
adapts ITMs to a subset of the $\pi$-calculus through its type system. In other
words, \emph{well-typed programs are expressible as ITMs}.

Typing judgements in ILC have the form $\Delta ; \Gamma |- e : A |> m$, where $\Delta$ is a
linear typing context and $m \in \{\Wm, \Rm, \Vm\}$ is a mode (write, read, and
value, respectively). The type system maintains the following two invariants.
\begin{enumerate}[leftmargin=*]
\item \emph{No duplication of read channel ends.} Each channel (or ``tape'' in
  ITM parlance) has a read end and a write end. The read end of the channel is
  protected against duplication by binding it in the linear context $\Delta$. This
  ensures that no non-determinism arises at the receiving end of communications.

\item \emph{No parallel composition of write mode processes.} The typing rules
  do not allow parallel composition of two write mode processes ($\Wm ||
  \Wm$). This ensures that no non-determinism arises at the sending end of
  communications.
\end{enumerate}

Together, the effect of these is that the only non-determinism in an ILC program
is due to random coinflips taken by the processes, which have a well-defined
distribution. This is essential to ensure that the normalization of an ILC
program has a computational interpretation, as is necessary in cryptography
reduction proofs. This also guarantees that any apparent concurrency hazards,
such as adversarial scheduling of messages in an asynchronous network, are due
to an explicit adversary process $\mc{A}$ rather than uncertainty built into the
model itself.

%In particular, the invariants maintained by the type system ensure that ILC
%programs are confluent, so any non-determinism in protocols is due to random
%coinflips taken by processes, which have a well-defined distribution. This is
%essential to ensure that the normalization of an ILC program has a computational
%interpretation, as is necessary in cryptographic reduction proofs. While some
%existing process calculi enjoy confluence properties, they are insufficient as a
%foundation for UC, because they either rule out nondeterminism entirely or are
%restricted to two-party
%communications~\cite{kobayashi1999linearity,bohl2016symbolic,fowler2018session}. On
%the other hand, ILC achieves confluence through its type system, which has the
%judgement form $\Delta ; \Gamma |- e : A |> m$, where $\Delta$ is a linear typing context and
%$m \in \{\Wm, \Rm, \Vm\}$ is a mode (write, read, and value, respectively), and
%boils down to the following two invariants:
%\begin{enumerate}[leftmargin=*]
%\item \emph{No duplication of read channel ends.} Each channel (or ``tape'' in
%  ITM parlance) has a read end and a write end. The read end of the channel is
%  protected against duplication by binding it in the linear context $\Delta$. This
%  ensures that no non-determinism arises at the receiving end of communications.
%
%\item \emph{No parallel composition of write mode processes.} The typing rules
%  do not allow parallel composition of two write mode processes ($\Wm ||
%  \Wm$). This ensures that no non-determinism arises at the sending end of
%  communications.
%\end{enumerate}

We have implemented an ILC interpreter in Haskell.

\begin{comment}
The success of blockchains and cryptocurrencies have raised interest in building
secure software systems that combine consensus protocols~\cite{miller2016honey},
zero-knowledge proofs~\cite{kosba2016hawk}, multiparty
computation~\cite{bentov2017instantaneous}, and other advanced techniques from
distributed computing and cryptography.  However, these primitives are known to
be error-prone and difficult to compose securely.  To the average developer,
reasoning about asynchronous, distributed, and adversarial deployment
environments is unnatural. On top of this, the security of a software system is
generally a whole-system property, but vulnerabilities often arise from
misunderstandings and mismatches as components are
integrated~\cite{chong2016report}.

Our solution is to develop a module system, \saucy, that will simplify the task
of composing distributed protocols and cryptographic primitives.  The novel
design idea of \saucy is to include with each module a rich behavioral
specification in the form of an \emph{ideal functionality}, which serves as a
self-contained specification of all desired security and liveness properties.
This idea is rooted in the theory of \emph{universal composability}
(UC)~\cite{canetti2001universally}, which is widely used in cryptography for
on-paper proofs, but has not yet been adapted for software engineering.  Based
on our prior experience providing formal specifications for smart contract and
blockchain protocols~\cite{bentov2017instantaneous, kosba2016hawk,
  miller2017sprites}, ideal functionalities are well-suited for modular design
of complex security-oriented applications for several reasons:

\begin{enumerate}
\item The UC framework is an established standard for modeling distributed and
  cryptographic protocols, so we can draw on existing literature for ideal
  functionality models.
\item Ideal functionalities are executable specifications, so they are amenable
  to property-based testing and machine-checkable proofs.
\item UC provides the strongest notion of security under concurrent
  composition. When we substitute an ideal functionality for a distributed
  protocol that realizes it, all the properties of the ideal functionality are
  preserved. Hence a developer's understanding of the ideal functionality
  carries over to the distributed implementation.
\end{enumerate}

\subsection{Our Approach}
\label{subsec:approach}

To reap the expected benefits of the \saucy module system, in this work, we will
develop infrastructure to help authors write, test, and verify distributed
protocol and cryptographic primitives.  This work will take place over three
main tasks: The first task focuses on designing a new high-level language called
ILC for expressing protocols and implementing the UC framework, the second
task focuses on developing testing techniques for detecting security and
liveness violations in the presence of Byzantine failures, and the third task
focuses on building a verification tool for mechanizing security and liveness
proofs in the UC framework.\smallskip

\subsection{Organization}
\label{subsec:org}

This paper is organized as follows. Section~\ref{sec:background} provides an
overview of the UC framework and potential applications.
Section~\ref{sec:challenges} highlights several challenges in using
UC. Section~\ref{sec:ilc} describes the design of our programming language
Interactive Lambda Calculus (ILC). Section~\ref{sec:session} describes an
extension of ILC with session types that will enable a form of verification for
ILC programs. Section~\ref{sec:testing} details our plan to develop new
techniques for testing security and liveness of ILC procotols in the presence of
Byzantine failures. Section~\ref{sec:verification} details our plan to develop a
proof assistant for mechanizing UC proofs.
\end{comment}
