\input{figures/ilc/modes}
\input{figures/ilc/types}
\input{figures/ilc/semantics}

\section{Interactive Lambda Calculus}
\label{sec:ilc}

We now present the Interactive Lambda Calculus in full, formalizing its syntax,
static semantics, and dynamic semantics.

\subsection{Syntax}
\label{subsec:syntax}

\input{figures/ilc/syntax}

The syntax of ILC given in Figure~\ref{fig:ilc-syntax} consists of types, modes,
and expressions.

Types are bifurcated into two kinds: one for intuitionistic types and one for
affine types. Intuitionistic types include $\tyUnit$, products
($\tyProd{A}{B}$), sums ($\tySum{A}{B}$), write channels $\tyWr{A}$, references
($\tyRef{A}$), and arrows ($\tyArr{A}{\footnotesize m}{B}$). Affine types
include read channels ($\tyRd{A}$), bang! types ($\tyBang{A}$), tensors
($\tyTensor{X}{Y}$), and lollipops ($\tyLolli{X}{\footnotesize m}{Y}$).

Modes consist $\Wm$ (write mode), $\Rm$ (read mode), and $\Vm$ (value mode). The
rules for composing modes (either sequentially or in parallel) are given in
Figure~\ref{fig:mode-composition}.

Expressions include variables (ranged over by $x$), the standard introduction
and elimination forms for intuitionistic functions, unit, products, and sums,
fixed point expressions, references, and two different let bindings. Affine
functions are introduced using $\eLAM{x}{e}$ and an intuitionistically typed
expression $e$ can be lifted into an affinely typed expression as
$\eBang{e}$. The expressions for message-passing and concurrency are these:
\begin{itemize}[leftmargin=*]
  \item \emph{Restriction:} $\eNu{(x_1, x_2)}{e}$ binds a read channel $x_1$ and
    write channel $x_2$ in $e$.
  \item \emph{Write:} $\eWr{e_1}{e_2}$ sends the result of evaluating $e_1$ on
    the write channel result of evaluating $e_2$.
  \item \emph{Read:} $\eLetRd{x_1}{x_2}{e_1}{e_2}$ reads a value from the read
    channel result of evaluating $e_1$, binding the value as $x_1$ and the read
    channel as $x_2$ in $e_2$.
  \item \emph{Fork:} $\eFork{e_1}{e_2}$ forks a child process $e_1$ and
    continues as $e_2$.
  \item \emph{Choice:} $\eChoice{e_1}{e_2}$ allows a process to continue as
    either $e_1$ or $e_2$ based on some initial read event in each of the
    processes.
\end{itemize}

%\begingroup
%\setlength\intextsep{0pt}
%\begin{wrapfigure}{r}{0.275\textwidth}
%  \lstinputlisting[style=myilc]{listings/loop.ilc}
%\end{wrapfigure}
%Note that replication ($!e$ in the $\pi$-calculus), which allows a process to
%spawn repeatedly, is not included for reasons we discuss in
%Section~\ref{subsec:types}. Instead, replication can be achieved through
%recursive definitions. For example, the recursive function \textsf{loop} (above)
%takes as arguments a read channel \textsf{c} and a function \textsf{f}. In the
%definition of \textsf{loop}, the let expression binds the value read from
%\textsf{c} to the variable \textsf{v} and rebinds the read channel to
%\textsf{c}; the body of the let expression applies the function \textsf{f} to
%the value \textsf{v}, and then repeats \textsf{loop}.\mypar
%\endgroup

\subsection{Static Semantics}
\label{subsec:types}

%\input{figures/ilc/syntax-types}

The type system of ILC is given in Figure~\ref{fig:type-expressions}. To
summarize, it maintains these invariants to ensure that \emph{well-typed ILC
  programs are expressible as ITMs}:
\begin{itemize}[leftmargin=*]
  \item No duplication of read channel ends.
  \item No parallel composition of write mode processes.
\end{itemize}

The intuitionistic typing judgement $\Delta ; \Gamma |- e : A |> m$ should be read as
follows:
\begingroup
\addtolength\leftmargini{-.2in}
\begin{quote}
  Under affine context $\Delta$ and intuitionistic context $\Gamma$, the expression $e$
  has intuitionistic type $A$ and mode $m$.
\end{quote}
\endgroup
\noindent The affine typing judgement follows similarly.

Before we jump into the typing rules, we point out that the mode composition
rules are given in Figure~\ref{fig:mode-composition}, which includes both
sequential and parallel mode composition. We will refer back to these later when
they hold relevance for certain typing rules. Moreover, we elide value mode
derivations to avoid clutter, so a judgement of the form $\Delta ; \Gamma |- e : A$ really
means $\Delta ; \Gamma |- e : A |> \Vm$.

The rules for intuitionistic variable lookup (var), unit (unit), and references
(ref, get, set) are standard, as are the introduction rules for products (pair)
and sums (inj). Notice that because these are all value mode expressions,
communication is not allowed in their subexpressions. On the other hand, the
elimination rules for products (split) and sums (case) do allow communication in
certain subexpressions, so it is possible to derive any mode.

The rule (abs) for intuitionistic lambda abstraction ($\eLam{x}{e}$) adds $x:A$
to the intuitionistic context $\Gamma$ before checking the body $e$, so if the body
$e$ has type $B$ and mode $m$, then the lambda abstraction has type
$\tyArr{A}{\footnotesize m}{B}$ and mode $\Vm$. What is noteworthy here is that
the mode of a function body is carried by its arrow type.

The dual application rule (app) says that applying a function, which carries a
mode $m$ over its arrow type, to an argument, which must have mode $\Vm$, yields
the mode $m$. And because lambda abstractions have mode $\Vm$, it follows that
partially applying a function also yields mode $\Vm$. This means that only the
rightmost arrow in a curried function type can carry a mode other than $\Vm$. In
light of this fact, we also elide value modes carried over arrows in function
signatures.

We gave a taste of let-expression typing when we introduced the letrd rule. The
rules for let and let! follow similarly, except they bind values in the
intuitionistic context (and obviously, they need not read from a channel). The
difference between let and let!, then, is that let binds an intuitionistic value
in an intuitionistic body, but let! unpacks an affine value with type
$\tyBang{A}$ to be used freely in an intuitionistic body. As with letrd, the
modes of both forms of let expressions are derived by sequentially composing the
mode of the bound expression with the mode of the body.

The rules for message passing concurrency are more interesting. The nu rule adds
the read-end of a channel $x_1: \tyRd{A}$ to the affine context $\Delta$ and its
corresponding write-end $x_2 : \tyWr{A}$ to the intuitionistic context $\Gamma$
before checking its body. We do not recap the wr and letrd rules here, but
recall that the wr rule derives the mode $\Wm$ and the read rule derives the
rule $\Rm$ as expected.

The fork rule says that that if we can appropriately split the affine context
such that the child process $e_1$ has type $A$ and mode $m_1$ and the
``continue'' process $e_2$ has type $B$ and mode $m_2$, then the whole
expression has type $B$ and mode $m_3$, which is derived by composing $m_1$ and
$m_2$ in parallel. Again, we emphasize that composing two write mode processes
in parallel violates type checking, i.e., $\Wm ;; \Wm => p$ cannot be derived
for any mode $p$.

Finally, the choice rule says that if we can appropriately split the affine
context such that both subexpressions $A$ and mode $R$, then the whole
expression follows exactly.

\subsection{Dynamic Semantics}
\label{subsec:semantics}

Figures~\ref{fig:configs} and~\ref{fig:semantics} define the dynamic semantics
of ILC. The top-level judgement $C_1 -> C_2$ should be read as ``configuration
$C_1$ steps to configuration $C_2$,'' where a configuration $C$ consists of a
set of communication channels $\Sigma$ (both read-ends and write-ends), a process
pool $\pi$, and a store $\sigma$ (a finite map from locations $\ell$ to
values). Configuration stepping uses an ancillary judgement for local stepping,
which covers cases in which the configuration does not change. \todo{?} The
local stepping judgement $\sigma_1; \e_1 \longrightarrow \sigma_2; \e_2$ should be read as ``under store
$\sigma_1$, expression $e_1$ steps to store $\sigma_{2}$ and expression
$e_2$. \todo{Explain evaluation contexts and read contexts}.

Local stepping has a standard call-by-value semantics. Configuration stepping is
more interesting. In the fork rule, the redex $\eFork{e_1}{e_2}$ in evaluation
context $E$ spawns a new process $e_1$ and steps to $E[e_2]$. In the nu rule,
the term $E[ \eNu{(x_1, x_2)}{e} ]$ reduces to $E[
  [\eChan{c_1}/x_1][\eChan{c_2}/x_2]e ]$, where $c_1$ and $c_2$ are fresh
channels added to $\Sigma$. In the rw rule, given that $c_2$ is the corresponding
write channel of $c_1$, denoted $c_2 \leadsto c_1$, the processes $E_1[R[
    \eRd{\eChan{c_1}}] ]$ and $E_2[ \eWr{\eChan{c_2}}{v}]$ step to the processes
$E_1[ (v, \eChan{c_1})]$ and $E_2[ \eUnit]$, respectively. \todo{Need to update
  this.}
