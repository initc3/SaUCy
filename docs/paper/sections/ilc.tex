\section{Interactive Lambda Calculus}
\label{sec:ilc}

\subsection{Program Syntax}
\label{subsec:syntax}

Figure~\ref{fig:ilc-syntax} gives the syntax of expressions. Expressions $e$
include variables $x$, primitive values $v$, channels $c$, the unit value $()$,
pairs (with elimination form \textsf{split}), sums (with elimination form
\textsf{case}), reference cells (with elimination form \textsf{get} and mutable
update \textsf{set}), thunks (with elimination form \textsf{force}), fixed
points, let binding, lambda abstraction, and function application. For
communication, expressions include restriction ($\eNu{(x_1, x_2)}{e}$), which
binds a a read channel $x_1$ and write channel $x_2$ in $e$; send
($\eWr{e_1}{e_2}$), which writes the result of evaluating $e_1$ on the channel
result of evaluating $e_2$; receive ($\eRd{e}$), which reads from the channel
result of evaluating $e$ and returns a pair consisting of the read value and the
read channel itself (see Section~\ref{subsec:types} for details); fork ($\eFork{e_1}{e_2}$), which creates a separate process $e_1$ and continues as $e_2$; external
choice ($\eChoice{e_1}{e_2}$), which allows a process to evolve as either $e_1$ or
$e_2$ (based on some initial event in each of the processes); and sequential
composition ($\eSeq{e_1}{e_2}$).

\begingroup
\setlength\intextsep{0pt}
\begin{wrapfigure}{r}{0.275\textwidth}
  \lstinputlisting[style=myilc]{listings/loop.ilc}
\end{wrapfigure}
Note that replication ($!e$ in the $\pi$-calculus), which allows a process to
spawn repeatedly, is not included for reasons we discuss in
Section~\ref{subsec:types}. Instead, replication can be achieved through
recursive definitions. For example, the recursive function \textsf{loop} (above)
takes as arguments a read channel \textsf{c} and a function \textsf{f}. In the
definition of \textsf{loop}, the let expression binds the value read from
\textsf{c} to the variable \textsf{v} and rebinds the read channel to
\textsf{c}; the body of the let expression applies the function \textsf{f} to
the value \textsf{v}, and then repeats \textsf{loop}.\mypar
\endgroup

\input{figures/ilc/syntax}

\subsection{Type System}
\label{subsec:types}

\input{figures/ilc/syntax-types}

\input{figures/ilc/syntax-modes}

\input{figures/ilc/type-expressions}

At a high level, ILC's type system adapts ITMs to a subset of the $\pi$-calculus.
The invariants maintained by the type system ensure that the only
non-determinism in an ILC program is due to random coinflips taken by processes,
which have a well-defined distribution. This is essential to ensure that the
normalization of an ILC program has a computational interpretation, as is
necessary in cryptographic reduction proofs. It guarantees that any apparent
concurrency hazards, such as adversarial scheduling of messages in an
asynchronous network, are due to an explicit adversary process $\mc{A}$ rather
than uncertainty built into the model itself.

Typing rules in ILC have the judgement form $\Delta ; \Gamma |- e : A |> m$, read as
``Under $\Delta$ and $\Gamma$, expression~$e$ has type $A$ and mode $m$''.  Here, $\Delta$
denotes a linear typing context, $\Gamma$ denotes a non-linear typing context, and
$m$ is one of three modes: value (\Vm), read (\Rm), and write
(\Wm). Importantly, these typing rules maintain the following two invariants:

\begin{enumerate}
\item \emph{No duplication of read channel ends.} In ILC, each channel (or
  ``tape'' in ITM parlance) has a read end and a write end. The read end of the
  channel is protected against duplication by binding it in the linear context
  $\Delta$. The notation $\Delta_1, \Delta_2$ denotes a partitioning of the read channels in
  $\Delta$. This ensures that no confusion (non-determinism) arises at the receiving
  end of a communication.

\item \emph{No parallel composition of write mode processes.} The typing rules
  do not allow parallel composition of two write mode processes ($\Wm ||
  \Wm$). This ensures that no confusion (non-determinism) arises at the sending
  end of a communication.

%\item \emph{No sequential composition of write mode processes.} The typing rules
%  do not allow sequential composition of two write mode processes ($\Wm ;;
%  \Wm$). This prevents the programmer from writing a process that gets ``stuck''
%  trying to perform writes in sequence---a writing process becomes inactive after
%  writing and can only reactivate when written to.
\end{enumerate}

\noindent Figure~\ref{fig:syntax--types} gives the syntax of types,
Figure~\ref{fig:syntax-modes} gives the syntax of modes and rules for mode
composition, and Figure~\ref{fig:type-expressions} gives the typing of
expressions (eliding value mode derivations).

\todo{Discuss syntax of types, linear typing rules and let!} The rule nu types a restriction as
$B |> m$ provided that body of the restriction ($e$) has type $B |> m$ under the
assumptions that $x_1$ is a read channel of type $\tyRd{A}$ in the linear
context and $x_2$ is a write channel of type $\tyWr{A}$ in the intuitionistic
context. The rule wr types a write expression as $\tyUnit |> \Wm$ provided that
the value being sent is compatible with the type of the write channel being sent
on. Additionally, the linear context $\Delta$ must be partitioned into contexts $\Delta_1$
and $\Delta_2$, which are used to type the subexpressions $e_1$ and $e_2$
respectively. The same pattern holds for the other typing rules as well. The rule rd types a read expression as $\tyProd{A}{\tyRd{A}} |> \Rm$, since it
returns a pair containing the value from the channel and the channel itself, so
that it can be rebound. Since read channels are typed linearly, returning and
rebinding read channels allows them to be used more than once. The rule fork is
types a fork as $B |> m_3$, where the type of the right process is $B$ (the type
of the left is ignored) and the mode $m_3$ is derived as the parallel
composition of the modes of the left and right processes ($m_1 || m_2 =>
m_3$). The rule choice is types an external choice as $A |> \Rm$ provided that
it is the type of the left and right processes. The rule seq types a sequence
similarly to the rule fork, except the mode $m_3$ is derived by sequential
composition of the modes of its sub-expressions.

The rule var looks up the binding of $x$ in the non-linear typing context $\Gamma$,
and the rule lvar looks up the binding of $x$ in the linear typing context
$\Delta$. The rules unit, pair, inj, and ref, get, and set are standard. The rules
split and case are standard, except for the fact that the body of a
\textsf{split} expression ($e_2$) and the branches of a \textsf{case} expression
($e_1$ and $e_2$) need not be value mode expressions (i.e., they can include
communication). Similarly, the rule fix allows fixed point expressions to
include communication. The rule let is the standard rule for typing let
bindings, except its mode is derived as $m1 ;; m2 => m3$, which is the
sequential composition of the mode of the bound expression ($e_1$) with the mode
of the body expression ($e_2$). The rule lam and app are standard, except a
function can include communication and arguments to a function must be value
mode expressions.

\lstinputlisting[style=myilc]{listings/repl.ilc}

\subsection{Dynamic Semantics}
\label{subsec:semantics}

\input{figures/ilc/semantics}

Figure~\ref{fig:semantics} gives the reduction semantics for ILC, which defines
a transition relation for \emph{configurations}. A configuration $C$ consists of
a set of communication channels $\Sigma$ and a process pool $\pi$. The main judgement
$C_1 \longrightarrow C_2$ can be read as ``configuration $C_1$ reduces to $C_2$.''
Configuration reduction uses an ancillary judgement for local reduction, which
covers cases in which the configuration does not change. The local reduction
judgement $\sigma_1; \e_1 \longrightarrow \sigma_2; \e_2$ can be read as ``under store $\sigma_1$,
expression $e_1$ reduces to $\sigma_{2}; e_2$. A store $\sigma$ consists of a finite map
from locations $\ell$ to to values. These rules are standard.

In the fork rule, a process with store $\sigma$ and redex $\eFork{e_1}{e_2}$ in
evaluation context $E$ spawns a new process $\sigma; e_1$ and reduces to $E[e_2]$. In
the nu rule, the term $E[ \eNu{(x_1, x_2)}{e} ]$ reduces to $E[
  [\eChan{c_1}/x_1][\eChan{c_2}/x_2]e ]$, where $c_1$ and $c_2$ are fresh
channels added to $\Sigma$. In the rw rule, given that $c_2$ is the corresponding
write channel of $c_1$, denoted $c_2 \leadsto c_1$, the processes $\sigma_1 ; E_1[R[
    \eRd{\eChan{c_1}}] ]$ and $\sigma_2 ; E_2[ \eWr{\eChan{c_2}}{v}]$ reduce to the
terms $\sigma_1 ; E_1[ (v, \eChan{c_1})]$ and $\sigma_2 ; E_2[ \eUnit]$, respectively.

\begin{comment}
\lstinputlisting[style=myilc]{listings/loop_seq_rd.ilc}


\lstinputlisting[style=myilc]{listings/async.ilc}

\input{listings/example_funcs}
\end{comment}

\input{figures/defn_execuc}
