\section{Interactive Lambda Calculus}
\label{sec:ilc}

We now present the Interactive Lambda Calculus in full, including its syntax,
static semantics, and dynamic semantics.

\subsection{Syntax}
\label{subsec:syntax}

\input{figures/ilc/syntax}

The syntax of ILC given in Figure~\ref{fig:ilc-syntax} consists of types, modes,
and expressions.

Types are bifurcated into two kinds: one for intuitionistic types and one for
linear types. Intuitionistic types include $\tyUnit$, products
($\tyProd{A}{B}$), sums ($\tySum{A}{B}$), write channels $\tyWr{A}$, references
($\tyRef{A}$), and arrows ($\tyArr{A}{\footnotesize m}{B}$). Linear types
include read channels ($\tyRd{A}$), bang! types ($\tyBang{A}$), tensors
($\tyTensor{X}{Y}$), and lollipops ($\tyLolli{X}{\footnotesize m}{Y}$).

Modes consist $\Wm$ (write mode), $\Rm$ (read mode), and $\Vm$ (value mode). The
rules for composing modes (either sequentially or in parallel) are given in
Figure~\ref{fig:mode-composition}.

Expressions include variables (ranged over by $x$) and the standard introduction
and elimination forms for intuitionistic functions, unit, products, and
sums. \todo{References, fixpoint.} Linear functions are introduced using
$\eLAM{x}{e}$ and an intuitionistically typed expression $e$ can be lifted into
a linearly typed expression as $\eBang{e}$. \todo{App for lollipops?}
Expressions for message passing concurrency are the following:
\begin{itemize}[leftmargin=*]
  \item \emph{Restriction:} $\eNu{(x_1, x_2)}{e}$ binds a read channel $x_1$ and
    write channel $x_2$ in $e$.
  \item \emph{Write:} $\eWr{e_1}{e_2}$ sends the result of evaluating $e_1$ on
    the write channel result of evaluating $e_2$.
  \item \emph{Read:} $\eLetRd{x_1}{x_2}{e_1}{e_2}$ reads a value from the read
    channel result of evaluating $e_1$, binding the value as $x_1$ and the read
    channel as $x_2$ in $e_2$.
  \item \emph{Fork:} $\eFork{e_1}{e_2}$ forks a child process $e_1$ and
    continues as $e_2$.
  \item \emph{Choice:} $\eChoice{e_1}{e_2}$ allows a process to continue as
    either $e_1$ or $e_2$ based on some initial read event in each of the
    processes.
\end{itemize}

%Expressions $e$ include variables $x$, primitive values $v$, channels
%$c$, the unit value $()$, pairs (with elimination form \textsf{split}), sums
%(with elimination form \textsf{case}), reference cells (with elimination form
%\textsf{get} and mutable update \textsf{set}), thunks (with elimination form
%\textsf{force}), fixed points, let binding, lambda abstraction, and function
%application. For communication, expressions include restriction ($\eNu{(x_1,
%  x_2)}{e}$), which binds a a read channel $x_1$ and write channel $x_2$ in $e$;
%send ($\eWr{e_1}{e_2}$), which writes the result of evaluating $e_1$ on the
%channel result of evaluating $e_2$; receive ($\eRd{e}$), which reads from the
%channel result of evaluating $e$ and returns a pair consisting of the read value
%and the read channel itself (see Section~\ref{subsec:types} for details); fork
%($\eFork{e_1}{e_2}$), which creates a separate process $e_1$ and continues as
%$e_2$; external choice ($\eChoice{e_1}{e_2}$), which allows a process to evolve
%as either $e_1$ or $e_2$ (based on some initial event in each of the processes);
%and sequential composition ($\eSeq{e_1}{e_2}$).

%\begingroup
%\setlength\intextsep{0pt}
%\begin{wrapfigure}{r}{0.275\textwidth}
%  \lstinputlisting[style=myilc]{listings/loop.ilc}
%\end{wrapfigure}
%Note that replication ($!e$ in the $\pi$-calculus), which allows a process to
%spawn repeatedly, is not included for reasons we discuss in
%Section~\ref{subsec:types}. Instead, replication can be achieved through
%recursive definitions. For example, the recursive function \textsf{loop} (above)
%takes as arguments a read channel \textsf{c} and a function \textsf{f}. In the
%definition of \textsf{loop}, the let expression binds the value read from
%\textsf{c} to the variable \textsf{v} and rebinds the read channel to
%\textsf{c}; the body of the let expression applies the function \textsf{f} to
%the value \textsf{v}, and then repeats \textsf{loop}.\mypar
%\endgroup

\subsection{Static Semantics}
\label{subsec:types}

%\input{figures/ilc/syntax-types}

\input{figures/ilc/modes}

\input{figures/ilc/type-expressions}

The type system of ILC is given in Figure~\ref{fig:type-expressions}. To
summarize, it maintains these invariants to ensure that \emph{well-typed ILC
  programs are expressible as ITMs}:
\begin{itemize}[leftmargin=*]
  \item No duplication of read channel ends.
  \item No parallel composition of write mode processes.
\end{itemize}

The main typing judgement $\Delta ; \Gamma |- e : A |> m$ should be read as follows:
\begingroup
\addtolength\leftmargini{-.2in}
\begin{quote}
  Under linear context $\Delta$ and intuitionistic context $\Gamma$, the expression $e$
  has intuitionistic type $A$ and mode $m$.
\end{quote}
\endgroup
\noindent (The typing judgement for linear types is analagous.) Note that we
elide value mode derivations in the typing rules to avoid clutter.

The rules for intuitionistic variable lookup (var), unit (unit), and references
(ref, get, set) are standard, as are the introduction rules for products (pair)
and sums (inj). Because these are all value mode expressions, communication is
not allowed in their subexpressions. On the other hand, the elimination rules
for products (split) and sums (case) do allow communication in certain
subexpressions, and so they can derive modes other than $\Vm$.

The rule (abs) for intuitionistic lambda abstraction ($\eLam{x}{e}$) adds $x:A$
to the intuitionistic context $\Gamma$ before checking the body $e$, so if the body
$e$ has type $B$ and mode $m$, then the abstraction has type
$\tyArr{A}{\footnotesize m}{B}$ and mode $\Vm$. What is noteworthy here is that
the mode of a function body is carried by its arrow type.

The dual application rule (app) says that applying a function, which carries a
mode $m$ over its arrow type, to an argument, which must have mode $\Vm$, yields
the mode $m$. And because a lambda abstraction has mode $\Vm$, it follows that
partially applying a function yields mode $\Vm$, so only the rightmost arrow in
a curried function type can carry a mode other than $\Vm$. In function
signatures, we elide value modes carried over arrows to avoid clutter.

The rule (let) for let binding is more interesting. It says that if we can split
the linear typing context into $\Delta_1,\Delta_2$ such that the local expression $e_1$
has type $A$ and mode $m_1$ under context $\Delta_1; \Gamma$, and the body $e_2$ has type
$B$ and mode $m_2$ under $\Delta_2 ; \Gamma, x:A$, then the entire let binding has type
$B$ and mode $m_3$ derived by sequentially composing $m_1$ and $m_2$. \todo{Mode
  composition.}

The let! rule is similar, except it allows us to unpack a value with linear type
$\tyBang{A}$ to be used in an unrestricted manner in a let-expression body.

The nu rule adds $x_1: \tyRd{A}$ to the linear context $\Delta$ and $x_2 : \tyWr{A}$
to the intuitionistic context $\Gamma$ before checking the body.

The fork rule says that that if we can split the linear typing context into
$\Delta_1, \Delta_2$ such that the child process $e_1$ has type $A$ and mode $m_1$ under
context $\Delta_1; \Gamma$, and the continuation of the process $e_2$ has type $B$ and
mode $m_2$ under context $\Delta_2; \Gamma$, then $\eFork{e_1}{e_2}$ has type $B$ and mode
$m_3$ derived by parallel composing $m_1$ and $m_2$. \todo{Parallel mode
  composition.}

The choice rule says that if we can split the linear typing context into $\Delta_1,
\Delta_2$ such that the left process $e_1$ has type $A$ and mode $\Rm$ under context
$\Delta_1; \Gamma$ and the right process $e_2$ has type $A$ and mode $\Rm$ under context
$\Delta_2; \Gamma$, then the whole expression has type $A$ and mode $\Rm$.

\begin{comment}
\todo{Discuss syntax of types, linear typing rules and let!} The rule nu types a
restriction as $B |> m$ provided that body of the restriction ($e$) has type $B
|> m$ under the assumptions that $x_1$ is a read channel of type $\tyRd{A}$ in
the linear context and $x_2$ is a write channel of type $\tyWr{A}$ in the
intuitionistic context. The rule wr types a write expression as $\tyUnit |> \Wm$
provided that the value being sent is compatible with the type of the write
channel being sent on. Additionally, the linear context $\Delta$ must be partitioned
into contexts $\Delta_1$ and $\Delta_2$, which are used to type the subexpressions $e_1$
and $e_2$ respectively. The same pattern holds for the other typing rules as
well. The rule rd types a read expression as $\tyProd{A}{\tyRd{A}} |> \Rm$,
since it returns a pair containing the value from the channel and the channel
itself, so that it can be rebound. Since read channels are typed linearly,
returning and rebinding read channels allows them to be used more than once. The
rule fork is types a fork as $B |> m_3$, where the type of the right process is
$B$ (the type of the left is ignored) and the mode $m_3$ is derived as the
parallel composition of the modes of the left and right processes ($m_1 || m_2
=> m_3$). The rule choice is types an external choice as $A |> \Rm$ provided
that it is the type of the left and right processes. The rule seq types a
sequence similarly to the rule fork, except the mode $m_3$ is derived by
sequential composition of the modes of its sub-expressions.

The rule var looks up the binding of $x$ in the non-linear typing context $\Gamma$,
and the rule lvar looks up the binding of $x$ in the linear typing context
$\Delta$. The rules unit, pair, inj, and ref, get, and set are standard. The rules
split and case are standard, except for the fact that the body of a
\textsf{split} expression ($e_2$) and the branches of a \textsf{case} expression
($e_1$ and $e_2$) need not be value mode expressions (i.e., they can include
communication). Similarly, the rule fix allows fixed point expressions to
include communication. The rule let is the standard rule for typing let
bindings, except its mode is derived as $m1 ;; m2 => m3$, which is the
sequential composition of the mode of the bound expression ($e_1$) with the mode
of the body expression ($e_2$). The rule lam and app are standard, except a
function can include communication and arguments to a function must be value
mode expressions.

\lstinputlisting[style=myilc]{listings/repl.ilc}
\end{comment}

\subsection{Dynamic Semantics}
\label{subsec:semantics}

\input{figures/ilc/semantics}

Figure~\ref{fig:semantics} gives the reduction semantics for ILC, which defines
a transition relation for \emph{configurations}. A configuration $C$ consists of
a set of communication channels $\Sigma$ and a process pool $\pi$. The main judgement
$C_1 \longrightarrow C_2$ can be read as ``configuration $C_1$ reduces to $C_2$.''
Configuration reduction uses an ancillary judgement for local reduction, which
covers cases in which the configuration does not change. The local reduction
judgement $\sigma_1; \e_1 \longrightarrow \sigma_2; \e_2$ can be read as ``under store $\sigma_1$,
expression $e_1$ reduces to $\sigma_{2}; e_2$. A store $\sigma$ consists of a finite map
from locations $\ell$ to to values. These rules are standard.

In the fork rule, a process with store $\sigma$ and redex $\eFork{e_1}{e_2}$ in
evaluation context $E$ spawns a new process $\sigma; e_1$ and reduces to $E[e_2]$. In
the nu rule, the term $E[ \eNu{(x_1, x_2)}{e} ]$ reduces to $E[
  [\eChan{c_1}/x_1][\eChan{c_2}/x_2]e ]$, where $c_1$ and $c_2$ are fresh
channels added to $\Sigma$. In the rw rule, given that $c_2$ is the corresponding
write channel of $c_1$, denoted $c_2 \leadsto c_1$, the processes $\sigma_1 ; E_1[R[
    \eRd{\eChan{c_1}}] ]$ and $\sigma_2 ; E_2[ \eWr{\eChan{c_2}}{v}]$ reduce to the
terms $\sigma_1 ; E_1[ (v, \eChan{c_1})]$ and $\sigma_2 ; E_2[ \eUnit]$, respectively.

\begin{comment}
\lstinputlisting[style=myilc]{listings/loop_seq_rd.ilc}


\lstinputlisting[style=myilc]{listings/async.ilc}

\input{listings/example_funcs}
\end{comment}

\input{figures/defn_execuc}
