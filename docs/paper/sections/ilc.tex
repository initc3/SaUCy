\input{figures/ilc/syntax}
\input{figures/ilc/modes}
\input{figures/ilc/types}
\input{figures/ilc/semantics}

\section{Interactive Lambda Calculus}
\label{sec:ilc}

We now present the Interactive Lambda Calculus in full, formalizing its syntax,
static semantics, and dynamic semantics.

\subsection{Syntax}
\label{subsec:syntax}

The syntax of ILC given in Figure~\ref{fig:ilc-syntax} consists of types, modes,
and expressions.

Types are bifurcated into two kinds: one for intuitionistic types (written $A$,
$B$) and one for affine types (written $X$, $Y$). The standard intuitionistic
types include unit ($\tyUnit$), products ($\tyProd{A}{B}$), and sums
($\tySum{A}{B}$). The more interesting ones are
write channels ($\tyWr{A}$) and arrows ($\tyArr{A}{\footnotesize m}{B}$), which
importantly carry a mode. Affine types include read channels ($\tyRd{A}$),
bang! types ($\tyBang{A}$), tensors ($\tyTensor{X}{Y}$), and lollipops
($\tyLolli{X}{\footnotesize m}{Y}$).

Modes consist of $\Wm$ (write mode), $\Rm$ (read mode), and $\Vm$ (value
mode). The rules for sequential and parallel composition of modes are given in
Figure~\ref{fig:mode-composition}.

The intuitionistic portion of ILC supports a fairly standard feature set. The
more interesting expressions are those related to affinity and message-passing
concurrency. Bang! types have introduction form $\eBang{e}$ and elimination form
$\eUnbang{e}$. Lollipops have introduction form $\eLam{\infty}{x}{e}$ and
elimination form $\eApp{e_1}{e_2}{\infty}$. Tensors have introduction form
$\ePair{e_1}{e_2}{\infty}$ and elimination form $\eSplit{\infty}{e_1}{x_1}{x_2}{e_2}$. The expressions for message-passing concurrency are these:
\begin{itemize}[leftmargin=*]
  \item \emph{Restriction:} $\eNu{(x_1, x_2)}{e}$ binds a read channel $x_1$ and
    a corresponding write channel $x_2$ in $e$.
  \item \emph{Write:} $\eWr{e_1}{e_2}$ sends the result of evaluating $e_1$ on
    the write channel result of evaluating $e_2$.
  \item \emph{Read:} $\eLetRd{x_1}{x_2}{e_1}{e_2}$ reads a value from the read
    channel result of evaluating $e_1$, binding the value as $x_1$ and the read
    channel as $x_2$ in $e_2$.
  \item \emph{Fork:} $\eFork{e_1}{e_2}$ forks a child process $e_1$ and
    continues as $e_2$.
  \item \emph{Choice:} $\eChoice{e_1}{e_2}$ allows a process to continue as
    either $e_1$ or $e_2$ based on some initial read event in each of the
    processes.
\end{itemize}

%\begingroup
%\setlength\intextsep{0pt}
%\begin{wrapfigure}{r}{0.275\textwidth}
%  \lstinputlisting[style=myilc]{listings/loop.ilc}
%\end{wrapfigure}
%Note that replication ($!e$ in the $\pi$-calculus), which allows a process to
%spawn repeatedly, is not included for reasons we discuss in
%Section~\ref{subsec:types}. Instead, replication can be achieved through
%recursive definitions. For example, the recursive function \textsf{loop} (above)
%takes as arguments a read channel \textsf{c} and a function \textsf{f}. In the
%definition of \textsf{loop}, the let expression binds the value read from
%\textsf{c} to the variable \textsf{v} and rebinds the read channel to
%\textsf{c}; the body of the let expression applies the function \textsf{f} to
%the value \textsf{v}, and then repeats \textsf{loop}.\mypar
%\endgroup

\subsection{Static Semantics}
\label{subsec:types}

%\input{figures/ilc/syntax-types}

The type system of ILC is given in Figure~\ref{fig:type-expressions}. The
intuitionistic typing judgment $\Delta ; \Gamma |- e : A |> m$ should be read as follows:
\begingroup
\addtolength\leftmargini{-.2in}
\begin{quote}
  Under affine context $\Delta$ and intuitionistic context $\Gamma$, the expression $e$
  has intuitionistic type $A$ and mode $m$.
\end{quote}
\endgroup
\noindent (The affine typing judgment follows similarly.) Importantly, the type
  system maintains these invariants:

\begin{comment}
Judgments have the form $\Delta ; \Gamma |- e : A |> m$, where $\Delta$ is an affine typing
context, $\Gamma$ is an intuitionistic typing context, and $m \in \{\Wm, \Rm, \Vm\}$ is
a mode (write, read, and value, respectively). Importantly, it maintains these
invariants:
\end{comment}

\begin{itemize}[leftmargin=*]
\item \emph{No duplication of read channel ends.} Each channel (or ``tape'' in
  ITM parlance) has a read end and a write end. The read end of the channel is
  protected against duplication by binding it in the affine context $\Delta$. This
  ensures that no nondeterminism arises at the receiving end of communications.

\item \emph{No parallel composition of write mode processes.} The typing rules
  do not allow parallel composition of two write mode processes ($\Wm ||
  \Wm$). This ensures that no nondeterminism arises at the sending end of
  communications.
\end{itemize}

\begin{comment}
To summarize, it maintains these invariants to ensure that \emph{well-typed ILC
programs are expressible as ITMs}:
\begin{itemize}[leftmargin=*]
  \item No duplication of read channel ends.
  \item No parallel composition of write mode processes.
\end{itemize}
\end{comment}

Before we go through a quick tour of the typing rules, we point out a few
things: Value mode derivations and ordinary type polymorphism are omitted to
avoid clutter, and algorithmic typing rules are given in the
Appendix.

\paragraph{Rules for preventing read nondeterminism.}
To protect read channels from duplication, the nu rule binds read channels in
the affine context. When reading from a channel, the letrd rule rebinds the
channel in the affine context so that it may be used again. The rules for typing
lambda abstractions (abs), fixed points (fix), and bang! types (bang) stipulate
that they must be closed with respect to affine variables. Otherwise, they could
violate the affinity of read channels.\smallskip

\paragraph{Rules for preventing write nondeterminism.}
The mode composition rules given in Figure~\ref{fig:mode-composition} prevent
write mode processes from being composed in parallel. This is reflected in the
fork rule, which derives the mode of $\eFork{e_1}{e_2}$ as the parallel
composition of the mode of $e_1$ and the mode of $e_2$.
To ensure this property is preserved during normalization, we must also forbid
sequential composition of write mode processes.

\begin{comment}
\paragraph{Intuitionistic rules.}
The rules for intuitionistic variable lookup (var), unit (unit), and references
(ref, get, set) are standard, as are the introduction rules for products (pair)
and sums (inj). Notice that because these are all value mode expressions,
communication is not allowed in their subexpressions. On the other hand, the
elimination rules for products (split) and sums (case) do allow communication in
certain subexpressions, so it is possible to derive any mode.

The rule (abs) for intuitionistic lambda abstraction ($\eLam{1}{x}{e}$) adds $x:A$
to the intuitionistic context $\Gamma$ before checking the body $e$, so if the body
$e$ has type $B$ and mode $m$, then the lambda abstraction has type
$\tyArr{A}{\footnotesize m}{B}$ and mode $\Vm$. There are two points worth
noting here. One is that the mode of the function body is carried by its arrow
type. The other is that the function body must be closed with respect to affine
variables, otherwise we would be able to duplicate read channels that are free
in the body. This similarly applies to the fix rule.

The dual application rule (app) says that applying a function, which carries a
mode $m$ over its arrow type, to an argument, which must have mode $\Vm$, yields
the mode $m$. And because lambda abstractions have mode $\Vm$, it follows that
partially applying a function also yields mode $\Vm$. This means that only the
rightmost arrow in a curried function type can carry a mode other than $\Vm$. In
light of this fact, we also elide value modes carried over arrows in function
signatures.

We gave a taste of let-expression typing when we introduced the letrd rule. The
rules for let and let! follow similarly, except they bind values in the
intuitionistic context (and obviously, they need not read from a channel). The
difference between let and let!, then, is that let binds an intuitionistic value
in an intuitionistic body, but let! unpacks an affine value with type
$\tyBang{A}$ to be used freely in an intuitionistic body. As with letrd, the
modes of both forms of let expressions are derived by sequentially composing the
mode of the bound expression with the mode of the body.

The rules for message passing concurrency are more interesting. The nu rule adds
the read-end of a channel $x_1: \tyRd{A}$ to the affine context $\Delta$ and its
corresponding write-end $x_2 : \tyWr{A}$ to the intuitionistic context $\Gamma$
before checking its body. We do not recap the wr and letrd rules here.

The fork rule says that that if we can appropriately split the affine context
such that the child process $e_1$ has type $A$ and mode $m_1$ and the
``continue'' process $e_2$ has type $B$ and mode $m_2$, then the whole
expression has type $B$ and mode $m_3$, which is derived by composing $m_1$ and
$m_2$ in parallel. Again, we emphasize that composing two write mode processes
in parallel violates type checking, i.e., $\Wm ;; \Wm => p$ cannot be derived
for any mode $p$.

Finally, the choice rule says that if we can appropriately split the affine
context such that both subexpressions $A$ and mode $R$, then the whole
expression follows exactly.

\paragraph{Affine rules.} The affine typing rules are, for the most part, analagous to their
intuitionistic counterparts. Two differences bear mentioning. First, the bang!
rule only lifts intuitionistically typed expressions that are closed with
respect to affine variables into an affinely typed expression. Otherwise, one
could wrap an intuitionistically typed expression with free affine variables in
a bang! and use it in an unrestricted manner. Second, in contrast with the abs
rule, the lollipop rule does not require function bodies to be free with respect
to affine variables.
\end{comment}

\subsection{Dynamic Semantics}
\label{subsec:semantics}

%\todo{Need some help explaining this subsection.} 
Figures~\ref{fig:configs} and~\ref{fig:semantics} define the dynamic syntax and semantics of ILC, respectively.
%
We define a \emph{configuration}~$C$ as a tuple of dynamic channel and process names~$\Sigma$
and a pool of running and terminated processes~$\pi$.

To state and prove the meta theory of ILC (\Secref{sec:metatheory}), we
extend the type system given above with typing rules for
configurations, including typing environments for channels. 
%
We omit these details here for space reasons, 
and we refer the interested reader to \Secref{sec:ilcproofs}.

We read the configuration reduction judgment $C_1 ---> C_2$ as ``configuration
$C_1$ steps to configuration $C_2$,'' 
%
and the local stepping judgment $e_1 \longrightarrow e_2$ 
for a single process~$e$ as ``expression $e_1$ steps to expression $e_2$.
%
The rules of local stepping follow a standard call-by-value semantics, 
where we streamline the definition with an evaluation context~$E$.

Configuration stepping consists of five rules, including a congruence
rule \Rule{congr} that permits some of the other rules to be simpler,
by making the order of the pool unimportant.
%
The other four rules consist of local stepping (via \Rule{local}),
creating new processes (via \Rule{fork}),
creating new channels (via \Rule{nu}),
and read-write interactions (via \Rule{rw}).
%
To avoid allocating the same name twice, 
the name set~$\Names$ records names of allocated channels and processes.
%
Rule~\Rule{rw} uses the syntax~$R$ for a combination of several (mutually exclusive) 
read-mode expressions, with a chosen read filling the (single) hole.
%
When synchronized, 
the rule uses this syntax to eliminate all of the unchosen read-mode expressions 
before control continues with the chosen read effect.
%
The relation $c_1 \leadsto c_2$ holds when 
channel names $c_1$ and $c_2$ refer to the 
write and read ends of a common channel.
%
(The rules abstract over how channel names, and this relation, are structured.)

%%% If you want more detail, you can uncomment this text below;
%%% However, it doesn't add much intuition beyond just reading each rule:

%% In the fork rule, the redex $\eFork{e_1}{e_2}$ in evaluation
%% context $E$ spawns a new process $e_1$ and continues by evaluating $E[e_2]$. 
%% %
%% In the nu rule,
%% the term $E[ \eNu{(x_1, x_2)}{e} ]$ reduces to $E[
%% [\eChan{c_1}/x_1][\eChan{c_2}/x_2]e ]$, where $c_1$ and $c_2$ are fresh channel ends
%% added to $\Sigma$. 
%% %
%% In the rw rule, given that $c_2$ is the corresponding write
%% channel of $c_1$, denoted $c_2 \leadsto c_1$, the processes $E_1[R[ \eRd{\eChan{c_1}}]
%% ]$ and $E_2[ \eWr{\eChan{c_2}}{v}]$ step to the processes $E_1[
%% (v, \eChan{c_1})]$ and $E_2[ \eUnit]$, respectively.
